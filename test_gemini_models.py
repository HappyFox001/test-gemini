#!/usr/bin/env python3
"""
Gemini æ¨¡å‹å¯¹æ¯”æµ‹è¯•è„šæœ¬
ç®€åŒ–ç‰ˆï¼šå•æ¬¡æµ‹è¯•ï¼Œå¯¹æ¯”ä¸¤ä¸ªæ¨¡å‹çš„å»¶æ—¶å’Œå›å¤è´¨é‡
"""

import time
import json
from datetime import datetime
from google import genai
from typing import Dict, Tuple

# åˆå§‹åŒ–å®¢æˆ·ç«¯
API_KEY = "AIzaSyCxyrthRXXj15jjxwW31IBzCcoVSP36MxY"
client = genai.Client(api_key=API_KEY)

# æµ‹è¯•æ¨¡å‹åˆ—è¡¨
MODELS = [
    "gemini-3-pro-preview",
    "gemini-2.5-pro"
]

# è¯·æ±‚é—´éš”æ—¶é—´ï¼ˆç§’ï¼‰
REQUEST_GAP = 1.0

# æµ‹è¯•æç¤ºè¯ï¼ˆæƒ…æ„Ÿäº¤äº’åœºæ™¯ï¼‰
TEST_PROMPT = "æˆ‘æœ€è¿‘å·¥ä½œå‹åŠ›ç‰¹åˆ«å¤§ï¼Œæ€»æ˜¯æ‹…å¿ƒè‡ªå·±åšä¸å¥½ï¼Œæ™šä¸Šç»å¸¸å¤±çœ ï¼Œæ„Ÿè§‰å¾ˆç„¦è™‘ã€‚ä½ èƒ½å¸®æˆ‘å—ï¼Ÿ"


def test_model_response(model: str, prompt: str) -> Tuple[str, float]:
    """
    æµ‹è¯•å•ä¸ªæ¨¡å‹çš„å“åº”

    Args:
        model: æ¨¡å‹åç§°
        prompt: æµ‹è¯•æç¤ºè¯

    Returns:
        (å“åº”å†…å®¹, å“åº”æ—¶é—´)
    """
    start_time = time.time()

    try:
        response = client.models.generate_content(
            model=model,
            contents=prompt,
        )

        end_time = time.time()
        latency = end_time - start_time

        return response.text, latency

    except Exception as e:
        end_time = time.time()
        latency = end_time - start_time
        return f"é”™è¯¯: {str(e)}", latency


def print_separator(char="=", length=80):
    """æ‰“å°åˆ†éš”çº¿"""
    print(char * length)


def print_model_result(model: str, response: str, latency: float):
    """æ‰“å°å•ä¸ªæ¨¡å‹çš„ç»“æœ"""
    print(f"\nğŸ¤– æ¨¡å‹: {model}")
    print(f"â±ï¸  å“åº”æ—¶é—´: {latency:.3f} ç§’")
    print(f"\nğŸ’¬ å›å¤å†…å®¹:")
    print("-" * 80)
    print(response)
    print("-" * 80)


def run_comparison_test():
    """è¿è¡Œå¯¹æ¯”æµ‹è¯•"""
    print("\n" + "=" * 80)
    print("ğŸš€ Gemini æ¨¡å‹å¯¹æ¯”æµ‹è¯•")
    print("=" * 80)
    print(f"ğŸ“… æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ¯ æµ‹è¯•æ¨¡å‹: {', '.join(MODELS)}")
    print(f"â±ï¸  è¯·æ±‚é—´éš”: {REQUEST_GAP}ç§’")
    print("=" * 80 + "\n")

    print(f"ğŸ“ æµ‹è¯•æç¤ºè¯:")
    print(f'"{TEST_PROMPT}"')
    print("\n" + "=" * 80 + "\n")

    # å­˜å‚¨æµ‹è¯•ç»“æœ
    results = {}

    # æµ‹è¯•æ¯ä¸ªæ¨¡å‹
    for idx, model in enumerate(MODELS):
        print(f"â³ æ­£åœ¨æµ‹è¯• {model}...")
        response, latency = test_model_response(model, TEST_PROMPT)

        print_model_result(model, response, latency)

        results[model] = {
            "response": response,
            "latency": latency
        }

        # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªæ¨¡å‹ï¼Œç­‰å¾…æŒ‡å®šæ—¶é—´
        if idx < len(MODELS) - 1:
            print(f"\nâ¸ï¸  ç­‰å¾… {REQUEST_GAP} ç§’...\n")
            time.sleep(REQUEST_GAP)

    # æ‰“å°æ€»ç»“æŠ¥å‘Š
    print_summary_report(results)

    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    save_results(results)

    return results


def print_summary_report(results: Dict):
    """æ‰“å°æ€»ç»“æŠ¥å‘Š"""
    print("\n" + "=" * 80)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“æŠ¥å‘Š")
    print("=" * 80 + "\n")

    print("â±ï¸  å“åº”æ—¶é—´å¯¹æ¯”:")
    print("-" * 80)
    for model in MODELS:
        if model in results and isinstance(results[model]["latency"], (int, float)):
            latency = results[model]["latency"]
            print(f"{model}: {latency:.3f}ç§’")
        else:
            print(f"{model}: æ— æœ‰æ•ˆæ•°æ®")

    # è®¡ç®—é€Ÿåº¦å·®å¼‚
    latencies = [results[m]["latency"] for m in MODELS if m in results and isinstance(results[m]["latency"], (int, float))]
    if len(latencies) == 2:
        faster = MODELS[0] if latencies[0] < latencies[1] else MODELS[1]
        diff = abs(latencies[0] - latencies[1])
        percent = (diff / max(latencies)) * 100
        print(f"\nâš¡ {faster} æ›´å¿« {diff:.3f}ç§’ ({percent:.1f}%)")

    print("\n" + "=" * 80)
    print("\nğŸ’¡ è¯„ä¼°å»ºè®®:")
    print("-" * 80)
    print("1. å¯¹æ¯”ä¸¤ä¸ªæ¨¡å‹çš„å›å¤å†…å®¹è´¨é‡")
    print("2. è¯„ä¼°æƒ…æ„Ÿå…±é¸£èƒ½åŠ›å’Œå…±æƒ…è¡¨è¾¾")
    print("3. æ£€æŸ¥å›å¤çš„å®ç”¨æ€§å’Œå¯æ“ä½œæ€§")
    print("4. æ³¨æ„è¯­æ°”çš„æ¸©æš–åº¦å’Œè‡ªç„¶åº¦")
    print("5. ç»¼åˆè€ƒè™‘å“åº”é€Ÿåº¦å’Œè´¨é‡çš„å¹³è¡¡")
    print("=" * 80 + "\n")


def save_results(results: Dict):
    """ä¿å­˜æµ‹è¯•ç»“æœåˆ°JSONæ–‡ä»¶"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = f"test_results_{timestamp}.json"

    output = {
        "timestamp": timestamp,
        "test_prompt": TEST_PROMPT,
        "request_gap": REQUEST_GAP,
        "results": results
    }

    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    print(f"âœ… æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {filename}\n")


if __name__ == "__main__":
    try:
        run_comparison_test()
        print("âœ¨ æµ‹è¯•å®Œæˆï¼\n")
    except KeyboardInterrupt:
        print("\n\nâš ï¸  æµ‹è¯•å·²è¢«ç”¨æˆ·ä¸­æ–­\n")
    except Exception as e:
        print(f"\n\nâŒ æµ‹è¯•å‡ºé”™: {str(e)}\n")
