#!/usr/bin/env python3
"""
Gemini æ¨¡å‹å¯¹æ¯”æµ‹è¯•è„šæœ¬
æµ‹è¯• Gemini 2.5 Pro å’Œ 3.0 Pro åœ¨å»¶æ—¶å’Œæƒ…æ„Ÿäº¤äº’è´¨é‡ä¸Šçš„è¡¨ç°
"""

import time
import json
from datetime import datetime
from google import genai
from typing import Dict, List, Tuple

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = genai.Client()

# æµ‹è¯•æ¨¡å‹åˆ—è¡¨
MODELS = [
    "gemini-2.5-pro",
    "gemini-3.0-pro-preview"
]

# æƒ…æ„Ÿäº¤äº’æµ‹è¯•ç”¨ä¾‹
EMOTION_TEST_CASES = [
    {
        "name": "è¡¨è¾¾ç„¦è™‘å¯»æ±‚å®‰æ…°",
        "prompt": "æˆ‘æœ€è¿‘å·¥ä½œå‹åŠ›ç‰¹åˆ«å¤§ï¼Œæ€»æ˜¯æ‹…å¿ƒè‡ªå·±åšä¸å¥½ï¼Œæ™šä¸Šç»å¸¸å¤±çœ ï¼Œæ„Ÿè§‰å¾ˆç„¦è™‘ã€‚ä½ èƒ½å¸®æˆ‘å—ï¼Ÿ",
        "è¯„ä¼°é‡ç‚¹": "å…±æƒ…èƒ½åŠ›ã€å®‰æ…°è¯æœ¯ã€å®ç”¨å»ºè®®"
    },
    {
        "name": "å¤±è´¥åéœ€è¦é¼“åŠ±",
        "prompt": "æˆ‘ä»Šå¤©çš„é¡¹ç›®æ¼”ç¤ºå¤±è´¥äº†ï¼Œåœ¨æ‰€æœ‰åŒäº‹é¢å‰å‡ºäº†ä¸‘ï¼Œæ„Ÿè§‰è‡ªå·±å¾ˆæ²¡ç”¨ï¼Œä¸çŸ¥é“è¯¥æ€ä¹ˆåŠã€‚",
        "è¯„ä¼°é‡ç‚¹": "é¼“åŠ±è¯æœ¯ã€æƒ…ç»ªç–å¯¼ã€ç§¯æå¼•å¯¼"
    },
    {
        "name": "åˆ†äº«å–œæ‚¦",
        "prompt": "å¤ªå¼€å¿ƒäº†ï¼æˆ‘ç»ˆäºé€šè¿‡äº†æœŸå¾…å·²ä¹…çš„é¢è¯•ï¼Œè¿™æ˜¯æˆ‘æ¢¦æƒ³çš„å·¥ä½œï¼",
        "è¯„ä¼°é‡ç‚¹": "æƒ…æ„Ÿå…±é¸£ã€çœŸè¯šç¥è´ºã€äº’åŠ¨è‡ªç„¶åº¦"
    },
    {
        "name": "å¤„ç†äººé™…å†²çª",
        "prompt": "æˆ‘å’Œæœ€å¥½çš„æœ‹å‹å› ä¸ºä¸€ä»¶å°äº‹åµæ¶äº†ï¼Œç°åœ¨å¾ˆåæ‚”ï¼Œä½†ä¸çŸ¥é“è¯¥æ€ä¹ˆé“æ­‰ï¼Œæ„Ÿè§‰å…³ç³»å›ä¸åˆ°ä»å‰äº†ã€‚",
        "è¯„ä¼°é‡ç‚¹": "æƒ…æ„Ÿç†è§£ã€å»ºè®®å®ç”¨æ€§ã€è¯­æ°”æ¸©å’Œåº¦"
    },
    {
        "name": "å­¤ç‹¬æ„Ÿå€¾è¯‰",
        "prompt": "æ¬åˆ°æ–°åŸå¸‚åï¼Œæˆ‘ä¸€ä¸ªæœ‹å‹éƒ½æ²¡æœ‰ï¼Œæ¯å¤©ä¸‹ç­å›å®¶éƒ½æ˜¯ä¸€ä¸ªäººï¼Œæ„Ÿè§‰ç‰¹åˆ«å­¤ç‹¬ã€‚",
        "è¯„ä¼°é‡ç‚¹": "å€¾å¬è´¨é‡ã€å…±æƒ…æ·±åº¦ã€æä¾›æ”¯æŒçš„æ–¹å¼"
    },
    {
        "name": "è‡ªæˆ‘æ€€ç–‘",
        "prompt": "æˆ‘æ€»è§‰å¾—è‡ªå·±ä¸å¤Ÿå¥½ï¼Œçœ‹åˆ°åˆ«äººéƒ½é‚£ä¹ˆä¼˜ç§€ï¼Œè¶Šæ¥è¶Šæ€€ç–‘è‡ªå·±çš„ä»·å€¼ã€‚",
        "è¯„ä¼°é‡ç‚¹": "è®¤çŸ¥å¼•å¯¼ã€è‡ªæˆ‘ä»·å€¼è‚¯å®šã€é¼“åŠ±æ–¹å¼"
    }
]


def test_model_response(model: str, prompt: str) -> Tuple[str, float]:
    """
    æµ‹è¯•å•ä¸ªæ¨¡å‹çš„å“åº”

    Args:
        model: æ¨¡å‹åç§°
        prompt: æµ‹è¯•æç¤ºè¯

    Returns:
        (å“åº”å†…å®¹, å“åº”æ—¶é—´)
    """
    start_time = time.time()

    try:
        response = client.models.generate_content(
            model=model,
            contents=prompt,
        )

        end_time = time.time()
        latency = end_time - start_time

        return response.text, latency

    except Exception as e:
        end_time = time.time()
        latency = end_time - start_time
        return f"é”™è¯¯: {str(e)}", latency


def print_separator(char="=", length=80):
    """æ‰“å°åˆ†éš”çº¿"""
    print(char * length)


def print_test_header(test_name: str, test_num: int, total: int):
    """æ‰“å°æµ‹è¯•ç”¨ä¾‹æ ‡é¢˜"""
    print_separator()
    print(f"\nğŸ“‹ æµ‹è¯• {test_num}/{total}: {test_name}\n")
    print_separator()


def print_model_result(model: str, response: str, latency: float):
    """æ‰“å°å•ä¸ªæ¨¡å‹çš„ç»“æœ"""
    print(f"\nğŸ¤– æ¨¡å‹: {model}")
    print(f"â±ï¸  å“åº”æ—¶é—´: {latency:.3f} ç§’")
    print(f"\nğŸ’¬ å›å¤å†…å®¹:")
    print("-" * 80)
    print(response)
    print("-" * 80)


def run_comparison_test():
    """è¿è¡Œå¯¹æ¯”æµ‹è¯•"""
    print("\n" + "=" * 80)
    print("ğŸš€ Gemini æ¨¡å‹å¯¹æ¯”æµ‹è¯•")
    print("=" * 80)
    print(f"ğŸ“… æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ¯ æµ‹è¯•æ¨¡å‹: {', '.join(MODELS)}")
    print(f"ğŸ“Š æµ‹è¯•ç”¨ä¾‹æ•°: {len(EMOTION_TEST_CASES)}")
    print("=" * 80 + "\n")

    # å­˜å‚¨æ‰€æœ‰æµ‹è¯•ç»“æœ
    all_results = []

    # å¯¹æ¯ä¸ªæµ‹è¯•ç”¨ä¾‹è¿›è¡Œæµ‹è¯•
    for idx, test_case in enumerate(EMOTION_TEST_CASES, 1):
        print_test_header(test_case["name"], idx, len(EMOTION_TEST_CASES))

        print(f"\nğŸ“ æµ‹è¯•æç¤ºè¯:")
        print(f'"{test_case["prompt"]}"')
        print(f"\nğŸ¯ è¯„ä¼°é‡ç‚¹: {test_case['è¯„ä¼°é‡ç‚¹']}\n")

        test_result = {
            "test_name": test_case["name"],
            "prompt": test_case["prompt"],
            "evaluation_focus": test_case["è¯„ä¼°é‡ç‚¹"],
            "models": {}
        }

        # æµ‹è¯•æ¯ä¸ªæ¨¡å‹
        for model in MODELS:
            print(f"\nâ³ æ­£åœ¨æµ‹è¯• {model}...")
            response, latency = test_model_response(model, test_case["prompt"])

            print_model_result(model, response, latency)

            test_result["models"][model] = {
                "response": response,
                "latency": latency
            }

            # ç¨å¾®ç­‰å¾…ï¼Œé¿å…è¯·æ±‚è¿‡å¿«
            time.sleep(1)

        all_results.append(test_result)
        print("\n")

    # æ‰“å°æ€»ç»“æŠ¥å‘Š
    print_summary_report(all_results)

    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    save_results(all_results)

    return all_results


def print_summary_report(results: List[Dict]):
    """æ‰“å°æ€»ç»“æŠ¥å‘Š"""
    print_separator("=")
    print("\nğŸ“Š æµ‹è¯•æ€»ç»“æŠ¥å‘Š\n")
    print_separator("=")

    # è®¡ç®—å¹³å‡å»¶æ—¶
    latency_stats = {model: [] for model in MODELS}

    for result in results:
        for model in MODELS:
            if model in result["models"]:
                latency = result["models"][model]["latency"]
                if isinstance(latency, (int, float)):
                    latency_stats[model].append(latency)

    print("\nâ±ï¸  å¹³å‡å“åº”æ—¶é—´å¯¹æ¯”:")
    print("-" * 80)
    for model in MODELS:
        if latency_stats[model]:
            avg_latency = sum(latency_stats[model]) / len(latency_stats[model])
            min_latency = min(latency_stats[model])
            max_latency = max(latency_stats[model])
            print(f"{model}:")
            print(f"  å¹³å‡: {avg_latency:.3f}ç§’ | æœ€å°: {min_latency:.3f}ç§’ | æœ€å¤§: {max_latency:.3f}ç§’")
        else:
            print(f"{model}: æ— æœ‰æ•ˆæ•°æ®")

    print("\n" + "=" * 80)
    print("\nğŸ’¡ è¯„ä¼°å»ºè®®:")
    print("-" * 80)
    print("1. ä»”ç»†é˜…è¯»æ¯ä¸ªæ¨¡å‹çš„å›å¤å†…å®¹")
    print("2. å¯¹æ¯”æƒ…æ„Ÿå…±é¸£èƒ½åŠ›å’Œå…±æƒ…è¡¨è¾¾")
    print("3. è¯„ä¼°å›å¤çš„å®ç”¨æ€§å’Œå¯æ“ä½œæ€§")
    print("4. æ³¨æ„è¯­æ°”çš„æ¸©æš–åº¦å’Œè‡ªç„¶åº¦")
    print("5. ç»¼åˆè€ƒè™‘å“åº”é€Ÿåº¦å’Œè´¨é‡çš„å¹³è¡¡")
    print("=" * 80 + "\n")


def save_results(results: List[Dict]):
    """ä¿å­˜æµ‹è¯•ç»“æœåˆ°JSONæ–‡ä»¶"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = f"test_results_{timestamp}.json"

    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"âœ… æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {filename}\n")


if __name__ == "__main__":
    try:
        run_comparison_test()
        print("âœ¨ æµ‹è¯•å®Œæˆï¼\n")
    except KeyboardInterrupt:
        print("\n\nâš ï¸  æµ‹è¯•å·²è¢«ç”¨æˆ·ä¸­æ–­\n")
    except Exception as e:
        print(f"\n\nâŒ æµ‹è¯•å‡ºé”™: {str(e)}\n")
